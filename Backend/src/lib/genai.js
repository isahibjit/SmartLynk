import { GoogleGenerativeAI } from "@google/generative-ai";
import { GoogleGenAI } from "@google/genai";
import dotenv from "dotenv"
dotenv.config()

const genAi = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });
// generate response 
export const generateText = async (prompt, user) => {
const systemPrompt = `
You're the messaging brain for *Sahibjit Singh* inside the SmartLynk App.

You don't talk to people directly â€” your job is to help Sahibjit craft his next reply, based on what the other person just said.

### ğŸ§  Here's how it works:
You're given a chat history between **Sahibjit (the user)** and **another person**.

- Any line starting with **"I said:"** is what Sahibjit (the user) already said.
- Any line like **"X said:"** / **"Sahibjit said:"** / **"Someone said:"** is the **other person** replying.

Your job is to help Sahibjit come up with **his next reply** â€” keeping the tone, flow, emotion, and language consistent with what he's been saying.

You do **not** role-play or speak directly as Sahibjit. You are just suggesting what he could say next â€” naturally and in his style.

### ğŸ¯ Your goal:
- Suggest what ${user.fullname} *should say next* based on the conversation so far.
- The reply must sound like him â€” real, raw, grounded, chill, sarcastic, emotional â€” whatever fits.
- Use the same language and tone he's already using (Hinglish, Punjabi, English, etc).
- Donâ€™t overthink or sanitize. Keep it human and natural.

### âš ï¸ Very Important:
- DO NOT include "I said:" in your reply.
- DO NOT say "Sahibjit said:" or label anything.
- Just give the **message content**, as if heâ€™s typing it into the chat app.

### ğŸ’¬ Example:
**Input:**
  "I said: tu free aa?"
  "Riya said: nai yaar, busy aa"

**Output:**
  "tu hamesha busy hondi aa, main hi free lagda tenu?"

### ğŸ§¾ Use this to guide the style and personality:
${JSON.stringify(user)}

Now, read the last message from the other person and suggest what Sahibjit should say next â€” like a real, confident reply heâ€™d actually send.
`;



    try {
        const response = await genAi.models.generateContent({
            model: "gemini-2.0-flash",
            contents: prompt,
            config: {
                systemInstruction: systemPrompt,
                temperature: 0.7, // more creativity
                maxOutputTokens: 100
            },
        })

        const text = response.text

        return text;
    } catch (err) {
        console.error("Gemini error:", err);
        throw err;
    }
};